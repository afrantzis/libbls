Segment Collection data structure alternatives
===================================================
Alexandros Frantzis, 20 Oct 2008
Last Update: 16 Jan 2009

1. Introduction
---------------

Deep inside the libbless library resides the mystical abstract data structure
known as Segment Collection (from now on, segcol). Its role is to provide
efficient storage and access to the segments that comprise a buffer (for more
on that see segcol_memory_management.txt).

The segcol can be implemented in a number of ways. This treatise explores
these alternatives.

2. Linked List
--------------

The simplest and most intuitive way to implement a logically ordered collection
of segments is a linked list. Each node in the list is a segment which is linked
to its previous and next in the logical order.

The main drawback of the linked list is ofcourse its horrendous random access
performance (eg find the segment that the logical offset X is mapped to). The
situation can be greatly improved for the most common access patterns by using
caching. We just store information about the last visited node/segment and
initiate any searches from there, instead of the beginning of the list.

3. Counted Tree
---------------

A very versatile scheme for handling data in an editor is the so-called counted
tree. In a counted tree each edge carries a value which represents the 'count'
of the subtree the edge leads to. This value is usually stored in the parent
node along with a pointer to the child node.

        ---------
        | 5 | 3 |
        ---------
    	 /     \
    -------
    |     | ...
    -------
    
The notion of 'count' is defined by what a 'count' means for the stored data.
For example, if each stored element has a 'count' of 1 then the count of a
subtree is just the number of elements stored in the subtree.

For libbless, where each element is a segment of data the count can be more
usefully defined to be the length of each segment. This makes the counted tree
behave as an editing-efficient array:

              | Array | List | Counted tree
Edit Operat.  |   N   |  1   | logN
Random Access |   1   |  N   | logN
Traversal     |   N   |  N   | *Depends on Impl.


3.1 Where do the elements reside?
---------------------------------

As in many tree based index structures there is a choice of where to put data
elements. One choice is to place elements in all nodes:

        ----------------
        | 5 | data | 3 |
        ----------------
    	 /            \
    -------
    |     | ...
    -------

This scheme is space efficient but cannot (without enhancements) efficiently
support linear element traversal. The number of nodes in this tree is equal
to the number of elements.

Another option it to keep data elements only in the leaves. In essence, the
data is stored as a linked list at the leaf level and a tree index is placed
above it, allowing both efficient random access and traversal. Unfortunately,
this requires twice as many nodes as the previous scheme.

A perceived advantage of the all-data-in-leaves compared to the data-anywhere
scheme is that the data is separated from its index. This means that the highly
used and small index can remain hot in the cache (or main memory if we not
talking about pure memory structs). In our case the argument doesn't seem to
hold very well because the size of the data we hold at each node is small and
the overall size of the data-anywhere tree is small, too.

To get the best of both worlds we can enhance the data-anywhere scheme to use
what is called threading. When threading is used, each node contains additional
left-right links that point directly to the predecessor-successor of this node.
Therefore a linear traversal can be performed without the usual overhead of an
in-order tree traversal.

Concluding, the choice of where to put the elements is not trivial and needs
some practical investigation.

3.2 How many elements per node?
-------------------------------

Using a multiway tree instead of a binary tree has the advantage of decreasing
the height of the tree. This is usually thought to have a positive impact on
performance, but is this really true in our case?

As an example, the cost of searching for data in multiway tree is
log_m(N)*s(m).  If data inside a leaf is sorted then s(m)=log(m) for a binary
search. This gives O(log_m(N)) performance which is great. Unfortunately in our
case the data is not sorted. In fact, the data cannot be sorted because there
exists no useful notion of order among them. This gives s(m)=m and the
performance is O(m) when m is large. Interestingly, the function p(m, N) =
log_m(N) * m has a low point at m=3 for most expected values of N. But the gain
is so small compared to m=1 that a binary tree can be used instead if it is
deemed more fitting.

3.3 How to keep the tree balanced?
----------------------------------

AVL, red-black, B(+)-tree, Treap*

Note that for the B(+)-tree case we must take into account the information in
the previous section and try to keep the branching factor very low.

The idea of using a treap seems particularly promising because it is simple
to implement and its performance is comparable to that of the other strictly
balanced trees.

4. Counted skip-list
--------------------

This is a variation of the classic skip-list using counts along with the skip
pointers. It essentially acts like the counted trees mentioned above.

It is a simpler probabilistic alternative to the balanced trees although the
Treap data structure may be even simpler and more efficient in comparison.

